iris+xorm文章
为什么选择iris框架？
最好的6个go语言web框架，对比学习曲线，核心功能，性能
iris在github上面例子比较多，beego也不少。
在核心功能上面iris比较丰富
性能方面iris和gin都是五颗星，性能比较好
很多人也不会选择用web框架，因为功能越多，越丰富，性能就越弱，很多没必要的性能可以舍弃，引入的web框架还是对原生的net/http包的封装，封装的越深，越多，性能也就越差，不用框架，也是对性能的考虑，但是在很多项目里面对性能要求还不至于那么极致。
我们使用web框架，能够帮我们更快搭建一个框架，更快的开发，更好的管理和维护，这些收益大于性能的时候，我们就会考虑使用框架。

iris常用功能介绍
安全认证
缓存
配置
cookie
文件
mvc
模版
丰富的路由规则

xorm工具，可以把数据表转换成go的struct,需要先设计好数据表，然后执行指令生成go model
安装程序：go get github.com/go-xorm/cmd/xorm
设置环境变量：go/bin加入到path路径下。
export PATH2="/Users/btcc/go/bin"
PATH=$PATH:$PATH1:$PATH2:
测试：xorm help
使用：xorm reverse mysql "root:123456@tcp(127.0.0.1:3306)/otc?charset=utf8" templates/goxorm/
    xorm reverse+驱动+连接信息+指定模版

如果go get不成功，就自己下载项目吧
把xorm下载下来，然后进入这个xorm目录下面执行指令,去models目录下面，拿到model信息
1. https://github.com/go-xorm/cmd.git
2. cd /Users/btcc/go/cmd/xorm
3. xorm reverse mysql "root:123456@tcp(127.0.0.1:3306)/otc?charset=utf8" templates/goxorm/





单利模式
先判断是否存在，存在就返回
不存在，加锁，然后去创建对象，再返回

但是如果一次请求十个过来，都是不存在，都在等待锁，只有一个请求可以加上锁，然后处理完了，其他九个请求依然会来创建对象，并返回。不严谨。
更好的做法是加锁之后，再检查一次
if aa!=nil{
	return aa
}
l.lock()
defer l.unlock()
if aa!=nil{
	return aa
}
//创建对象，返回



基于ab或者wrk的压力测试
apache服务自带的ab
wrk https://github.com/wg/wrk

f12可以看到每个请求的时间
request-sent 发送时间
waitting 等待时间
content download 下载时间

 安装wrk：brew search wrk

ab -h 查看帮助文档
-n：总共测试多少个请求
-c：并发多少
ab -n10000 -c10  http://localhost:8000/api/member/v1/show
结果：
Requests per second:    5736.87 [#/sec] (mean)

wrk
-c 多少连接
-t 并发数
-d 持续时间
wrk -c10 -t10 -d5 http://localhost:8000/api/member/v1/show
结果
Requests/sec:  10553.71

ab默认短连接，wrk默认长连接
wrk请求结束继续发，不会断开请求
ab请求结果就中断了，重新建立一个连接

只要查看请求数量就行了，然后去做优化，再测试看看请求数量是否可以增加

集群
单机缓存不一致的问题，注意更新xorm缓存

利用负载均衡服务器构建集群
利用nginx的tcp反向代理来实现
lvs也可以做反向代理，但是只能在lunix系统做，性能比nginx更好，但是nginx在很多情况下都是可以满足要求的。

使用dns和cnd做加速
dns解析的时候，可以分配到不同的服务器
cnd缓存集群并且离用户最近

优化
对数据源增加redis缓存，减少对mysql的依赖和读写。
大量的数据读取和存储可以使用redis，比如奖品信息，优惠券信息，用户信息，ip黑名单，今日抽奖次数等等。
原子性操作， redis的递增，递减也优于mysql。
但是redis增加缓存，也就是增加了一层冗余数据，通过空间换时间，特别注意要保证数据同步

可以全量缓存，也可以散列（分散到不同的key上，控制每个key的数据量，提高效率）部分缓存
奖品数据全量缓存，json序列化成string，因为奖品是有顺序的，使用hash不合适，list也没有任何优势。
奖品数据更新频率很低，没有必要把每个奖品分开维护
gift-service 增加三个方法：getAllByCache，setAllByCache，updateByCache
修改读取方式，增加useCache bool参数
修改数据的时候，记得清空缓存

单个用户数据的缓存，hash结构（一次只 读取/更新 部分字段，而且不需要json系列化）
用户数据不合适做全量缓存，用户数据数量大，而且更新频率大
user-service 增加三个方法：getByCache，setByCache，updateByCache

ip黑名单 hash结构 blackkip_service
user-service 增加三个方法：getByCache，setByCache，updateByCache
修改和洗白也需要更新黑名单缓存

ip今日抽奖次数 hash IncrIpLuckyNum原子性递增用户今日抽奖次数
用户今日抽奖次数 hash InitUserLuckyNum 从数据库初始化缓存数据
为什么IP抽奖次数不需要存储数据库，而用户今日抽奖次数必须要存储数据库呢？
ip限制是多个人共同的操作，这个值很大，多一点少一点没关系，而用户的限制就比较严格，用户限制也需要每日清空 restGroupUserList
同时user的数据库结构使用hash，使用散列，使每个hash结构尽量小一点，提高redis执行效率。

优惠券的全量缓存，不需要顺序，使用set集合，增加就set进去，拿出来就删掉了，场景比较合适
ImportCacheCodes
RecacheCodes
GetCacheCodeNum

发奖计划数据维护
精确到每分钟到发奖计划 其实每分钟，每天的计划应该不一样，根据请求数量来确定一个概率种子会更好点

抽奖的时候，可以免费，也可以消耗一些虚拟币
与优惠券，推广码结合等等

所有用户获得大奖的概率一样，不合理。
有大奖，就会有很多新用户，如果大奖被他们抽去了，显然不合理，新用户抽完奖就不会在你平台了，我们还是要有一些认为规则
注册时间超过多少天，用户等级 等等

发奖的时候，如果一开始大量用户进来，奖都没有了，这样显然也不合理，所以加上发奖计划就比较合理

wrk压力测试之后发现很多环节的耗时，其中看到了redis性能很高，数据库的性能比较差，那么做优化的时候，是不是可以考虑更多的使用redis呢？
如果数据要求精度不高，性能更好的时候，就使用redis，比如用户黑名单，减少数据库的依赖
某些条件可以限制很多用户，那么就放在前面，也可以提高性能 比如每日ip限制，用户限制等等。
日志输出也会影响性能，减少不必要的日志输出
取随机数，也是耗时的地方

业务逻辑
业务逻辑多，qps，并发肯定就上不去，时间就会比较长，需要我们平衡，是要更快，还是要更完善


